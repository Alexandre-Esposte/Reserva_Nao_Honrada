{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_path = \"../datasets_for_ml/\"\n",
    "\n",
    "reservas_futuras = pd.read_csv(datasets_path+'reservas_futuras.csv')\n",
    "transacoes = pd.read_csv(datasets_path+'transacoes.csv')\n",
    "cancelados = pd.read_csv(datasets_path+'cancelados.csv')\n",
    "faltantes = pd.read_csv(datasets_path+'faltantes.csv')\n",
    "\n",
    "transacoes['Date'] = pd.to_datetime(transacoes['Date'])\n",
    "cancelados['Booking Date'] = pd.to_datetime(cancelados['Booking Date'])\n",
    "cancelados['Cancel Date'] = pd.to_datetime(cancelados['Cancel Date'])\n",
    "faltantes['Date'] = pd.to_datetime(faltantes['Date'])\n",
    "reservas_futuras['Date'] = pd.to_datetime(reservas_futuras['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vimos na análise dos dados que há interseções entre as tabelas de transações, cancelados e faltantes. Entretanto, suspeitamos que essas tabelas deveriam ser mutuamente exclusivas, de tal forma que não deveria haver interseções entre elas.\n",
    "\n",
    "Vamos tomar a seguinte estratégia para lidar com esse problema:\n",
    "\n",
    "* Todas as interseções de cancelados e faltantes com transações serão removidos, deixando as instâncias somente na tabela transações. Pois se o cliente está na tabela de transações significa que ele recebeu o serviço, portanto, não cancelou e nem faltou.\n",
    "\n",
    "* Os clientes que estão na interseção de cancelados e faltantes serão removidos da tabela de faltantes e mantidos na tabela de cancelados. Se o cliente está na lista de cancelados, significa que ele cancelou e, portanto, não faltou."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando flags para auxiliar na remoção das instâncias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1862, 13), (240, 7), (59, 4))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apenas para controle\n",
    "transacoes.shape , cancelados.shape , faltantes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancelados['to_remove'] = cancelados.index\n",
    "faltantes['to_remove'] = faltantes.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de interseções entre cancelados e transacoes: 56\n"
     ]
    }
   ],
   "source": [
    "remove = pd.merge(left = cancelados[['Booking Date','Code','to_remove']], \n",
    "               right = transacoes[['Date','Client']],\n",
    "               left_on = ['Code','Booking Date'], \n",
    "               right_on=['Client','Date'],\n",
    "               how='inner',\n",
    "               indicator=True).drop_duplicates()['to_remove']\n",
    "\n",
    "\n",
    "print(f\"Quantidade de interseções entre cancelados e transacoes: {len(remove)}\")\n",
    "\n",
    "cancelados = cancelados.drop(remove)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de interseções entre faltantes e transacoes: 1\n"
     ]
    }
   ],
   "source": [
    "remove = pd.merge(left = faltantes[['Date','Code','to_remove']], \n",
    "               right = transacoes[['Date','Client']],\n",
    "               left_on = ['Code','Date'], \n",
    "               right_on=['Client','Date'],\n",
    "               how='inner',\n",
    "               indicator=True).drop_duplicates()['to_remove']\n",
    "\n",
    "\n",
    "print(f\"Quantidade de interseções entre faltantes e transacoes: {len(remove)}\")\n",
    "faltantes = faltantes.drop(remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de interseções entre cancelados e transacoes: 4\n"
     ]
    }
   ],
   "source": [
    "remove = pd.merge(left = cancelados[['Booking Date','Code']], \n",
    "               right = faltantes[['Date','Code','to_remove']],\n",
    "               left_on = ['Code','Booking Date'], \n",
    "               right_on=['Code','Date'],\n",
    "               how='inner',\n",
    "               indicator=True).drop_duplicates()['to_remove']\n",
    "\n",
    "\n",
    "print(f\"Quantidade de interseções entre cancelados e transacoes: {len(remove)}\")\n",
    "faltantes = faltantes.drop(remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancelados = cancelados.drop('to_remove',axis=1)\n",
    "faltantes = faltantes.drop('to_remove',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1862, 13), (184, 7), (54, 4))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apenas para controle\n",
    "transacoes.shape , cancelados.shape , faltantes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota-se que não há mais interseções entre as tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transações vs cancelados\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cancel Date</th>\n",
       "      <th>Code</th>\n",
       "      <th>Service</th>\n",
       "      <th>Staff_x</th>\n",
       "      <th>Booking Date</th>\n",
       "      <th>Canceled By</th>\n",
       "      <th>Days</th>\n",
       "      <th>Receipt</th>\n",
       "      <th>Date</th>\n",
       "      <th>Description</th>\n",
       "      <th>...</th>\n",
       "      <th>Staff_y</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Amount</th>\n",
       "      <th>GST</th>\n",
       "      <th>PST</th>\n",
       "      <th>mes_nome</th>\n",
       "      <th>mes_n</th>\n",
       "      <th>dia_nome</th>\n",
       "      <th>dia_n</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Cancel Date, Code, Service, Staff_x, Booking Date, Canceled By, Days, Receipt, Date, Description, Client, Staff_y, Quantity, Amount, GST, PST, mes_nome, mes_n, dia_nome, dia_n, _merge]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------- \n",
      "Transações vs faltantes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Code</th>\n",
       "      <th>Service</th>\n",
       "      <th>Staff_x</th>\n",
       "      <th>Receipt</th>\n",
       "      <th>Description</th>\n",
       "      <th>Client</th>\n",
       "      <th>Staff_y</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Amount</th>\n",
       "      <th>GST</th>\n",
       "      <th>PST</th>\n",
       "      <th>mes_nome</th>\n",
       "      <th>mes_n</th>\n",
       "      <th>dia_nome</th>\n",
       "      <th>dia_n</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Code, Service, Staff_x, Receipt, Description, Client, Staff_y, Quantity, Amount, GST, PST, mes_nome, mes_n, dia_nome, dia_n, _merge]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------- \n",
      "Faltantes vs cancelados\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cancel Date</th>\n",
       "      <th>Code</th>\n",
       "      <th>Service_x</th>\n",
       "      <th>Staff_x</th>\n",
       "      <th>Booking Date</th>\n",
       "      <th>Canceled By</th>\n",
       "      <th>Days</th>\n",
       "      <th>Date</th>\n",
       "      <th>Service_y</th>\n",
       "      <th>Staff_y</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Cancel Date, Code, Service_x, Staff_x, Booking Date, Canceled By, Days, Date, Service_y, Staff_y, _merge]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Transações vs cancelados')\n",
    "display(pd.merge(left = cancelados, \n",
    "               right = transacoes,\n",
    "               left_on = ['Code','Booking Date'], \n",
    "               right_on=['Client','Date'],\n",
    "               how='inner',\n",
    "               indicator=True))\n",
    "\n",
    "print(\"-\"*100,'\\nTransações vs faltantes')\n",
    "display(pd.merge(left = faltantes, \n",
    "               right = transacoes,\n",
    "               left_on = ['Code','Date'], \n",
    "               right_on=['Client','Date'],\n",
    "               how='inner',\n",
    "               indicator=True))\n",
    "\n",
    "print(\"-\"*100,'\\nFaltantes vs cancelados')\n",
    "display(pd.merge(left = cancelados, \n",
    "               right = faltantes,\n",
    "               left_on = ['Code','Booking Date'], \n",
    "               right_on=['Code','Date'],\n",
    "               how='inner',\n",
    "               indicator=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "faltantes = faltantes.rename({'Code':'Client'},axis=1)\n",
    "cancelados = cancelados.rename({'Code':'Client','Booking Date': \"Booking_Date\"},axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Construção do dataset para treinamento, teste e validação 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Obter a data mais recente de cada cliente, seja de serviço, falta ou cancelamento\n",
    "\n",
    "2. Utilizar as datas passadas como histórico e obter informações relevantes desses dados\n",
    "\n",
    "3. A não existência de um dataset com as reservas adiciona uma dificuldade a mais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "767 120 45\n"
     ]
    }
   ],
   "source": [
    "cancelados_clientes = cancelados['Client'].unique().tolist()\n",
    "faltantes_clientes = faltantes['Client'].unique().tolist()\n",
    "transacoes_clientes = transacoes['Client'].unique().tolist()\n",
    "\n",
    "clientes = transacoes_clientes\n",
    "\n",
    "print(len(transacoes_clientes), len(cancelados_clientes), len(faltantes_clientes))\n",
    "\n",
    "c = 0\n",
    "for cliente_cancelado in cancelados_clientes:\n",
    "\n",
    "    if cliente_cancelado not in clientes:\n",
    "        clientes.append(cliente_cancelado)\n",
    "\n",
    "\n",
    "for cliente_faltante in clientes:\n",
    "\n",
    "    if cliente_faltante not in clientes:\n",
    "        clientes.append(cliente_faltante)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame({'Client':clientes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Client</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KERT01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COOM01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PEDM01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BAIS01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FRAL01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>CARS01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>SHMS01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>COLS01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>ROUT01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>MIRY01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>798 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Client\n",
       "0    KERT01\n",
       "1    COOM01\n",
       "2    PEDM01\n",
       "3    BAIS01\n",
       "4    FRAL01\n",
       "..      ...\n",
       "793  CARS01\n",
       "794  SHMS01\n",
       "795  COLS01\n",
       "796  ROUT01\n",
       "797  MIRY01\n",
       "\n",
       "[798 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = transacoes.groupby('Client')['Date'].max().to_frame('Transacao_mais_recente').reset_index()\n",
    "dataset = pd.merge(dataset,aux,how='left',on='Client')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = faltantes.groupby('Client')['Date'].max().to_frame('Falta_mais_recente').reset_index()\n",
    "dataset = pd.merge(dataset,aux,how='left',on='Client')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = cancelados.groupby('Client')['Booking_Date'].max().to_frame('Cancelamento_mais_recente').reset_index()\n",
    "dataset = pd.merge(dataset,aux,how='left',on='Client')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Client</th>\n",
       "      <th>Transacao_mais_recente</th>\n",
       "      <th>Falta_mais_recente</th>\n",
       "      <th>Cancelamento_mais_recente</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KERT01</td>\n",
       "      <td>2018-06-20</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COOM01</td>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PEDM01</td>\n",
       "      <td>2018-06-09</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BAIS01</td>\n",
       "      <td>2018-06-09</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FRAL01</td>\n",
       "      <td>2018-06-09</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>CARS01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-05-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>SHMS01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-07-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>COLS01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-04-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>ROUT01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-06-17</td>\n",
       "      <td>2018-05-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>MIRY01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-05-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>798 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Client Transacao_mais_recente Falta_mais_recente  \\\n",
       "0    KERT01             2018-06-20                NaT   \n",
       "1    COOM01             2018-06-15                NaT   \n",
       "2    PEDM01             2018-06-09                NaT   \n",
       "3    BAIS01             2018-06-09                NaT   \n",
       "4    FRAL01             2018-06-09                NaT   \n",
       "..      ...                    ...                ...   \n",
       "793  CARS01                    NaT                NaT   \n",
       "794  SHMS01                    NaT                NaT   \n",
       "795  COLS01                    NaT                NaT   \n",
       "796  ROUT01                    NaT         2018-06-17   \n",
       "797  MIRY01                    NaT                NaT   \n",
       "\n",
       "    Cancelamento_mais_recente  \n",
       "0                         NaT  \n",
       "1                         NaT  \n",
       "2                         NaT  \n",
       "3                         NaT  \n",
       "4                         NaT  \n",
       "..                        ...  \n",
       "793                2018-05-25  \n",
       "794                2018-07-13  \n",
       "795                2018-04-22  \n",
       "796                2018-05-06  \n",
       "797                2018-05-19  \n",
       "\n",
       "[798 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.fillna(0)\n",
    "dataset['Transacao_mais_recente'] = pd.to_datetime(dataset['Transacao_mais_recente'])\n",
    "dataset['Falta_mais_recente'] = pd.to_datetime(dataset['Falta_mais_recente'])\n",
    "dataset['Cancelamento_mais_recente'] = pd.to_datetime(dataset['Cancelamento_mais_recente'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora estamos aptos a determinar qual foi a data da interação mais recente de cada cliente com o salão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interacao_mais_recente(transacao,faltante,cancelado):\n",
    "\n",
    "    if transacao > faltante and transacao > cancelado:\n",
    "        return transacao,'compareceu'\n",
    "    \n",
    "    elif faltante > cancelado and faltante > transacao:\n",
    "        return faltante,'faltou'\n",
    "\n",
    "    elif cancelado > faltante and cancelado > transacao:\n",
    "        return cancelado,'cancelou'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = dataset.apply(lambda x: interacao_mais_recente(x['Transacao_mais_recente'],x['Falta_mais_recente'],x['Cancelamento_mais_recente']),axis=1)\n",
    "\n",
    "datas = []\n",
    "evento = []\n",
    "\n",
    "for i in resultado:\n",
    "    datas.append(i[0])\n",
    "    evento.append(i[1])\n",
    "\n",
    "dataset['data_recente'] = datas\n",
    "dataset['evento'] = evento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(['Transacao_mais_recente','Falta_mais_recente','Cancelamento_mais_recente'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisamos estabelecer o target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_target(evento, qt_dias = None ):\n",
    "    if evento == 'compareceu':\n",
    "        return 0\n",
    "    elif evento == 'faltou':\n",
    "        return 1\n",
    "    \n",
    "    elif evento == 'cancelou':\n",
    "        if qt_dias < 2:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "def obtem_dias(cliente,data):\n",
    "\n",
    "    return cancelados.query(f\"Booking_Date == '{data}' and Client == '{cliente}' \")['Days'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['dias'] = dataset.apply(lambda x: obtem_dias(x['Client'],x['data_recente']) if x['evento'] == 'cancelou' else np.nan, axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['target'] = dataset.apply(lambda x: define_target(x['evento'],x['dias']),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (essa solução será removida, considerar a de cima )**Construção do dataset para treinamento, teste e validação**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo do projeto consiste em desenvolver um classificador que seja capaz de identificar os clientes que não sigam as políticas do salão. Portanto, as únicas informações que teremos acesso para realizar essa predição será o histórico do cliente e as informações passadas por ele no momento da reserva.\n",
    "\n",
    "Logo, o histórico do cliente será de muita importância para o nosso desenvolvimento. Portanto, não podemos simplesmente elaborar um dataset de treino considerando todas as instâncias das tabelas, uma vez que existe uma relação temporal nos dados mesmo que o problema não se configure com o de uma série temporal.\n",
    "\n",
    "Dito isso, vamos seguir da seguinte maneira:\n",
    "\n",
    "> 1. Vamos separar os primeiros quatro meses (Março a Junho) para elaborar o dataset de treino. Os meses subsequentes serão utilizados para teste.\n",
    "\n",
    "> 2. Com a tabela de faltantes vamos criar uma flag para realizar a contagem de quantas vezes um dado cliente faltou durante os 3 meses de referência. Podemos obter também o staff e serviço mais frequente durante esse histórico de faltas. \n",
    "\n",
    "> 3. Com a tabela de cancelados podemos gerar uma flag informando quantas vezes um determinado cliente cancelou. Podemos obter a média/mediana da diferença entre as datas de cancelamento e reserva, o staff mais frequente e o serviço mais frequente.\n",
    "\n",
    "> 4. Com a tabela transações conseguimos obter as métricas de recência, frequência e valor, o staff e dia mais frequentes além da quantidade de serviços prestado por dia.\n",
    "\n",
    "\n",
    "O target será composto por um valor binário, o valor zero corresponderá aos clientes que seguiu a política do salão e o valor um corresponderá aos clientes que não seguiram a política do salão.\n",
    "\n",
    "Desse modo, será atribuído o target igual a 1 para todas as instâncias que  tiverem o número de faltas acima de 0 e/ou as instâncias cujas diferenças entre a data de reserva e de cancelamento são menores que dois dias. Serão atribuídas o valor 0 para as demais instâncias.\n",
    "\n",
    "\n",
    "Como vimos no EDA, a tabela reservas futuras corresponde justamente às reservas realizadas pelos cientes. A princípio não pretendo utilizar essa tabela, dado que o treino e o teste eu consigo das demais tabelas. Entretanto, o que receberíamos em produção seria justamente a tabela de reservas futuras. Com essa tabela conseguimos rastrear o histórico do cliente e efetuar a predição.\n",
    "\n",
    "Outro questão se estabelece que a tabela de reservas futuras contabiliza somente os cliente que reservaram e não faltaram, portanto, não vejo muita utilidade em utilizar essa tabela por agora\n",
    "\n",
    "Um ponto de observação é importante. Clientes que nunca foram ao salão não apresentam histórico, desse modo, precisaríamos lidar com essa situação em produção. Ao meu ver, o mais prudente seria não realizar a estimativa para esses novos clientes, uma vez que não há o histórico deles.\n",
    "\n",
    "Observação: No EDA concluímos que o nosso intervalo de tempo compreende 136 dias ou pouco mais de 4 meses. Entretanto, esses dias estão distribuídos ao longo de Março a Julho. Esse pequeno detalhe pode gerar algumas dúvidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "transacoes_train = transacoes[transacoes['Date'].apply(lambda x: x.month <= 6)]\n",
    "transacoes_test = transacoes[transacoes['Date'].apply(lambda x: x.month > 6)]\n",
    "\n",
    "cancelados_train = cancelados[cancelados['Booking Date'].apply(lambda x: x.month <= 6)]\n",
    "cancelados_test =  cancelados[cancelados['Booking Date'].apply(lambda x: x.month >6)]\n",
    "\n",
    "faltantes_train = faltantes[faltantes['Date'].apply(lambda x: x.month <= 6)]\n",
    "faltantes_test =  faltantes[faltantes['Date'].apply(lambda x: x.month > 6)]\n",
    "\n",
    "\n",
    "train = pd.DataFrame()\n",
    "test = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['cliente'] = transacoes_train['Client'].unique()\n",
    "\n",
    "test['cliente'] = transacoes_test['Client'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((650, 1), (321, 1))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conferindo a seguir os meses para os datasets de treino  e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['March', 'April', 'June', 'May'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transacoes_train['mes_nome'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['July'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transacoes_test['mes_nome'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos iniciar da tabela mais simples para a tabela mais complicada. Vamos começar por faltantes\n",
    "\n",
    "1. Calcular a quantidade de vezes que houve falta por cliente\n",
    "\n",
    "2. Staff mais frequente\n",
    "\n",
    "3. Serviço mais frequente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Code'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m qt_faltas \u001b[39m=\u001b[39m faltantes_train\u001b[39m.\u001b[39;49mgroupby(\u001b[39m'\u001b[39;49m\u001b[39mCode\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39msize()\u001b[39m.\u001b[39mto_frame(\u001b[39m'\u001b[39m\u001b[39mqte_faltas\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mreset_index()\n\u001b[1;32m      2\u001b[0m train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmerge(left \u001b[39m=\u001b[39m train,right \u001b[39m=\u001b[39m qt_faltas, left_on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcliente\u001b[39m\u001b[39m'\u001b[39m,right_on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCode\u001b[39m\u001b[39m'\u001b[39m,how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m train \u001b[39m=\u001b[39m train\u001b[39m.\u001b[39mfillna(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/Área de Trabalho/projetos_ds/desonra/venv/lib/python3.10/site-packages/pandas/core/frame.py:8872\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   8869\u001b[0m \u001b[39mif\u001b[39;00m level \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m by \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   8870\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou have to supply one of \u001b[39m\u001b[39m'\u001b[39m\u001b[39mby\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlevel\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 8872\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[1;32m   8873\u001b[0m     obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   8874\u001b[0m     keys\u001b[39m=\u001b[39;49mby,\n\u001b[1;32m   8875\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   8876\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   8877\u001b[0m     as_index\u001b[39m=\u001b[39;49mas_index,\n\u001b[1;32m   8878\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m   8879\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[1;32m   8880\u001b[0m     observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[1;32m   8881\u001b[0m     dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[1;32m   8882\u001b[0m )\n",
      "File \u001b[0;32m~/Área de Trabalho/projetos_ds/desonra/venv/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:1273\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1270\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropna \u001b[39m=\u001b[39m dropna\n\u001b[1;32m   1272\u001b[0m \u001b[39mif\u001b[39;00m grouper \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1273\u001b[0m     grouper, exclusions, obj \u001b[39m=\u001b[39m get_grouper(\n\u001b[1;32m   1274\u001b[0m         obj,\n\u001b[1;32m   1275\u001b[0m         keys,\n\u001b[1;32m   1276\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   1277\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   1278\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m   1279\u001b[0m         observed\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m observed \u001b[39mis\u001b[39;49;00m lib\u001b[39m.\u001b[39;49mno_default \u001b[39melse\u001b[39;49;00m observed,\n\u001b[1;32m   1280\u001b[0m         dropna\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropna,\n\u001b[1;32m   1281\u001b[0m     )\n\u001b[1;32m   1283\u001b[0m \u001b[39mif\u001b[39;00m observed \u001b[39mis\u001b[39;00m lib\u001b[39m.\u001b[39mno_default:\n\u001b[1;32m   1284\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(ping\u001b[39m.\u001b[39m_passed_categorical \u001b[39mfor\u001b[39;00m ping \u001b[39min\u001b[39;00m grouper\u001b[39m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m~/Área de Trabalho/projetos_ds/desonra/venv/lib/python3.10/site-packages/pandas/core/groupby/grouper.py:1009\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1007\u001b[0m         in_axis, level, gpr \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, gpr, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1009\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1010\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(gpr, Grouper) \u001b[39mand\u001b[39;00m gpr\u001b[39m.\u001b[39mkey \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1011\u001b[0m     \u001b[39m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m     exclusions\u001b[39m.\u001b[39madd(gpr\u001b[39m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Code'"
     ]
    }
   ],
   "source": [
    "qt_faltas = faltantes_train.groupby('Code').size().to_frame('qte_faltas').reset_index()\n",
    "train = pd.merge(left = train,right = qt_faltas, left_on='cliente',right_on='Code',how='left')\n",
    "train = train.fillna(0)\n",
    "train = train.drop('Code',axis=1)\n",
    "\n",
    "\n",
    "qt_faltas = faltantes_test.groupby('Code').size().to_frame('qte_faltas').reset_index()\n",
    "test = pd.merge(left = test,right = qt_faltas, left_on='cliente',right_on='Code',how='left')\n",
    "test = test.fillna(0)\n",
    "test = test.drop('Code',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_moda = faltantes_train.groupby('Code').apply(lambda x: x['Service'].mode()[0]).to_frame('moda_servico_faltante').reset_index()\n",
    "train = pd.merge(left = train,right = service_moda, left_on='cliente',right_on='Code',how='left')\n",
    "train = train.drop('Code',axis=1)\n",
    "\n",
    "service_moda = faltantes_test.groupby('Code').apply(lambda x: x['Service'].mode()[0]).to_frame('moda_servico_faltante').reset_index()\n",
    "test = pd.merge(left = test,right = service_moda, left_on='cliente',right_on='Code',how='left')\n",
    "test = test.drop('Code',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "staff_moda = faltantes_train.groupby('Code').apply(lambda x: x['Staff'].mode()[0]).to_frame('moda_staff_faltante').reset_index()\n",
    "train = pd.merge(left = train,right = staff_moda, left_on='cliente',right_on='Code',how='left')\n",
    "train = train.drop('Code',axis=1)\n",
    "\n",
    "staff_moda = faltantes_test.groupby('Code').apply(lambda x: x['Staff'].mode()[0]).to_frame('moda_staff_faltante').reset_index()\n",
    "test = pd.merge(left = test,right = staff_moda, left_on='cliente',right_on='Code',how='left')\n",
    "test = test.drop('Code',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos para os cancelados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Calcular o serviço mais frequente\n",
    "\n",
    "2. Staff mais frequente\n",
    "\n",
    "3. Staff que cancelou mais frequente\n",
    "\n",
    "4. A média da antecedência de cancelamento\n",
    "\n",
    "5. Quantidade de vezes que cancelou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = cancelados_train.groupby('Code').apply(lambda x: x['Service'].mode()[0]).to_frame('moda_servico_cancelado').reset_index()\n",
    "train = pd.merge(left = train,right = aux, left_on='cliente',right_on='Code',how='left')\n",
    "train = train.drop('Code',axis=1)\n",
    "\n",
    "\n",
    "aux = cancelados_test.groupby('Code').apply(lambda x: x['Service'].mode()[0]).to_frame('moda_servico_cancelado').reset_index()\n",
    "test = pd.merge(left = test,right = aux, left_on='cliente',right_on='Code',how='left')\n",
    "test = test.drop('Code',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = cancelados_train.groupby('Code').apply(lambda x: x['Staff'].mode()[0]).to_frame('moda_staff_cancelado').reset_index()\n",
    "train = pd.merge(left = train,right = aux, left_on='cliente',right_on='Code',how='left')\n",
    "train = train.drop('Code',axis=1)\n",
    "\n",
    "\n",
    "aux = cancelados_test.groupby('Code').apply(lambda x: x['Staff'].mode()[0]).to_frame('moda_staff_cancelado').reset_index()\n",
    "test = pd.merge(left = test,right = aux, left_on='cliente',right_on='Code',how='left')\n",
    "test = test.drop('Code',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = cancelados_train.groupby('Code').apply(lambda x: x['Service'].mode()[0]).to_frame('moda_staff_cancelador_cancelado').reset_index()\n",
    "train = pd.merge(left = train,right = aux, left_on='cliente',right_on='Code',how='left')\n",
    "train = train.drop('Code',axis=1)\n",
    "\n",
    "aux = cancelados_test.groupby('Code').apply(lambda x: x['Service'].mode()[0]).to_frame('moda_staff_cancelador_cancelado').reset_index()\n",
    "test = pd.merge(left = test,right = aux, left_on='cliente',right_on='Code',how='left')\n",
    "test = test.drop('Code',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = cancelados_train.groupby('Code')['Days'].mean().to_frame('antecedencia').reset_index()\n",
    "train = pd.merge(left = train,right = aux, left_on='cliente',right_on='Code',how='left')\n",
    "train = train.drop('Code',axis=1)\n",
    "\n",
    "aux = cancelados_test.groupby('Code')['Days'].mean().to_frame('antecedencia').reset_index()\n",
    "test = pd.merge(left = test,right = aux, left_on='cliente',right_on='Code',how='left')\n",
    "test = test.drop('Code',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = cancelados_train.groupby('Code').size().to_frame('qte_cancelamento').reset_index()\n",
    "train = pd.merge(left = train,right = aux, left_on='cliente',right_on='Code',how='left')\n",
    "train = train.drop('Code',axis=1)\n",
    "train['qte_cancelamento'] = train['qte_cancelamento'].fillna(0)\n",
    "\n",
    "aux = cancelados_test.groupby('Code').size().to_frame('qte_cancelamento').reset_index()\n",
    "test = pd.merge(left = test,right = aux, left_on='cliente',right_on='Code',how='left')\n",
    "test = test.drop('Code',axis=1)\n",
    "test['qte_cancelamento'] = train['qte_cancelamento'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos para a tabela transacoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Calcular a média da quantidade de serviços por dia (receipt)\n",
    "\n",
    "2. Calcular o Staff mais frequente\n",
    "\n",
    "3. Calcular recência\n",
    "\n",
    "4. Calcular frequência\n",
    "\n",
    "5. Calcular valor\n",
    "\n",
    "6. Calcular o dia_nome mais frequente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transacoes_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = transacoes_train.groupby(['Client','Date'])['Receipt'].size().groupby('Client').mean().to_frame('qte_servicos_por_dia').reset_index()\n",
    "train = pd.merge(left = train,right = aux, left_on='cliente',right_on='Client',how='left')\n",
    "train = train.drop('Client',axis=1)\n",
    "\n",
    "aux = transacoes_test.groupby(['Client','Date'])['Receipt'].size().groupby('Client').mean().to_frame('qte_servicos_por_dia').reset_index()\n",
    "test = pd.merge(left = test,right = aux, left_on='cliente',right_on='Client',how='left')\n",
    "test = test.drop('Client',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = transacoes_train.groupby('Client').apply(lambda x: x['Staff'].mode()[0]).to_frame('moda_staff_prestou_servico').reset_index()\n",
    "train = pd.merge(left = train,right = aux, left_on='cliente',right_on='Client',how='left')\n",
    "train = train.drop('Client',axis=1)\n",
    "\n",
    "aux = transacoes_test.groupby('Client').apply(lambda x: x['Staff'].mode()[0]).to_frame('moda_staff_prestou_servico').reset_index()\n",
    "test = pd.merge(left = test,right = aux, left_on='cliente',right_on='Client',how='left')\n",
    "test = test.drop('Client',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = transacoes_train.groupby('Client').apply(lambda x: x['dia_nome'].mode()[0]).to_frame('moda_dia').reset_index()\n",
    "train = pd.merge(left = train,right = aux, left_on='cliente',right_on='Client',how='left')\n",
    "train = train.drop('Client',axis=1)\n",
    "\n",
    "\n",
    "aux = transacoes_test.groupby('Client').apply(lambda x: x['dia_nome'].mode()[0]).to_frame('moda_dia').reset_index()\n",
    "test = pd.merge(left = test,right = aux, left_on='cliente',right_on='Client',how='left')\n",
    "test = test.drop('Client',axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora resta calcular frequência e valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Valor, media, mediana, desvio padrão, max e min\n",
    "aux = transacoes_train.groupby('Client')['Amount'].agg(['mean','median','std','max','min'])\n",
    "train = pd.merge(left = train,right = aux, left_on='cliente',right_on='Client',how='left')\n",
    "\n",
    "\n",
    "aux = transacoes_test.groupby('Client')['Amount'].agg(['mean','median','std','max','min'])\n",
    "test = pd.merge(left = test,right = aux, left_on='cliente',right_on='Client',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequencia\n",
    "\n",
    "aux = transacoes_train.groupby('Client').size().to_frame('frequencia')\n",
    "train = pd.merge(left = train,right = aux, left_on='cliente',right_on='Client',how='left')\n",
    "\n",
    "aux = transacoes_test.groupby('Client').size().to_frame('frequencia')\n",
    "test = pd.merge(left = test,right = aux, left_on='cliente',right_on='Client',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "desonra",
   "language": "python",
   "name": "desonra"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "02ad4af985444ed67ca1dd01d1eb956ee597f940faec3793a177cb96aedb1ed4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
